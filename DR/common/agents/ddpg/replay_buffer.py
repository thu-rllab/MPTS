import numpy as np

# Code based on:
# https://github.com/openai/baselines/blob/master/baselines/deepq/replay_buffer.py


# Simple replay buffer
class ReplayBuffer(object):
    def __init__(self, max_size=1e6):
        self.storage = []
        self.max_size = int(max_size)
        self.next_idx = 0

    # Expects tuples of (state, next_state, action, reward, done)
    def add(self, data):
        if self.next_idx >= len(self.storage):
            self.storage.append(data)
        else:
            self.storage[self.next_idx] = data

        self.next_idx = (self.next_idx + 1) % self.max_size

    def sample(self, batch_size=100, gdroweight=None):
        ind = np.random.randint(0, len(self.storage), size=batch_size)
        if gdroweight is not None:
            x, y, u, r, d, ret = [], [], [], [], [], []

            for i in ind:
                X, Y, U, R, D, Ret = self.storage[i]
                x.append(np.array(X, copy=False))
                y.append(np.array(Y, copy=False))
                u.append(np.array(U, copy=False))
                r.append(np.array(R, copy=False))
                d.append(np.array(D, copy=False))
                ret.append(np.array(Ret, copy=False))

            return np.array(x), np.array(y), np.array(u), np.array(r).reshape(-1, 1), np.array(d).reshape(-1, 1), np.array(ret).reshape(-1, 1)
        else:
            x, y, u, r, d = [], [], [], [], []

            for i in ind:
                X, Y, U, R, D = self.storage[i]
                x.append(np.array(X, copy=False))
                y.append(np.array(Y, copy=False))
                u.append(np.array(U, copy=False))
                r.append(np.array(R, copy=False))
                d.append(np.array(D, copy=False))

            return np.array(x), np.array(y), np.array(u), np.array(r).reshape(-1, 1), np.array(d).reshape(-1, 1)